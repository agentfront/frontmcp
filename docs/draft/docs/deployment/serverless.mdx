---
title: Serverless Deployment
slug: deployment/serverless
icon: cloud
---

Deploy your FrontMCP server to serverless platforms like Vercel, AWS Lambda, and Cloudflare Workers.

## Supported Platforms

| Platform           | Status       | Module Format | Config File              |
| ------------------ | ------------ | ------------- | ------------------------ |
| Vercel             | Stable       | ESM           | `vercel.json`            |
| AWS Lambda         | Stable       | ESM           | `ci/template.yaml` (SAM) |
| Cloudflare Workers | Experimental | CommonJS      | `wrangler.toml`          |

## Quick Start

<Tip>
**New project?** Use `frontmcp create` with the `--target` flag to scaffold a serverless-ready project:

```bash
# Vercel project
npx frontmcp create my-app --target vercel

# AWS Lambda project (generates SAM template)
npx frontmcp create my-app --target lambda

# Cloudflare Workers project
npx frontmcp create my-app --target cloudflare
```

This generates the platform config files (`vercel.json`, `ci/template.yaml`, or `wrangler.toml`) automatically.

</Tip>

<Tabs>
  <Tab title="Vercel">
    ```bash
    # Build for Vercel
    frontmcp build --adapter vercel

    # Deploy
    vercel deploy
    ```

  </Tab>
  <Tab title="AWS Lambda">
    ```bash
    # Install required dependency
    npm install @codegenie/serverless-express

    # Build for Lambda
    frontmcp build --adapter lambda

    # Deploy with your preferred tool (SAM, CDK, Serverless Framework)
    ```

  </Tab>
  <Tab title="Cloudflare">
    ```bash
    # Build for Cloudflare Workers
    frontmcp build --adapter cloudflare

    # Deploy
    wrangler deploy
    ```

  </Tab>
</Tabs>

## Vercel

Vercel is a popular platform for deploying serverless functions with excellent DX.

<Info>
For persistent session storage on Vercel, see [Vercel KV Setup](/docs/deployment/vercel-kv) for an edge-compatible alternative to Redis.
</Info>

### Setup

<Steps>
  <Step title="Build your project">
    ```bash
    frontmcp build --adapter vercel
    ```
  </Step>
  <Step title="Inspect the generated outputs">
    ```
    dist/
      main.js      # Compiled server entry
      index.js     # Serverless handler wrapper
    .vercel/output/
      config.json
      functions/
        index.func/
          handler.cjs
          .vc-config.json
    vercel.json    # Deployment settings
    ```

    The CLI now emits a complete [Vercel Build Output API v3](https://vercel.com/docs/build-output-api/v3) tree, so you no longer need to hand-maintain `/api` folders or launch scripts.

  </Step>
  <Step title="Deploy with Vercel CLI or dashboard">
    ```bash
    vercel deploy
    ```
  </Step>
</Steps>

### Generated vercel.json

```json
{
  "version": 2,
  "installCommand": "pnpm install",
  "buildCommand": "pnpm run build"
}
```

<Info>
The CLI auto-detects your package manager via lockfiles (`bun.lockb`, `pnpm-lock.yaml`, `yarn.lock`, `package-lock.json`). If none are present it defaults to npm, so the generated commands always match how you already build locally.
</Info>

<Note>
You can customize this file after generation. The build command will not overwrite existing config files.
</Note>

### Build Output Layout

The generated `.vercel/output` directory matches the structure Vercel expects at deploy time:

```
.vercel/output/
├── config.json                # Routes all requests to the index function
└── functions/
    └── index.func/
        ├── handler.cjs        # Bundled handler and chunks
        └── .vc-config.json    # Node.js 22 runtime definition
```

Because the CLI writes the Build Output API tree for you, you can upload the folder as-is (for example via `vercel deploy --prebuilt`) without relying on legacy routing fallbacks.

### How It Works

The generated `index.js` wrapper:

1. Sets `FRONTMCP_SERVERLESS=1` environment variable
2. Imports your compiled `main.js` (which runs the `@FrontMcp` decorator)
3. Exports an async handler that retrieves the Express app and forwards requests

```javascript
// Generated dist/index.js (simplified)
process.env.FRONTMCP_SERVERLESS = '1';
import './main.js';
import { getServerlessHandlerAsync } from '@frontmcp/sdk';

export default async function handler(req, res) {
  const app = await getServerlessHandlerAsync();
  return app(req, res);
}
```

The Vercel adapter now also runs a post-bundle hook that copies every artifact in `dist/` into `.vercel/output/functions/index.func/`, adds `.vc-config.json`, and writes `config.json`. That keeps CI uploads, local `vercel deploy --prebuilt`, and Dockerized builds consistent without extra scripting.

## AWS Lambda

Deploy to AWS Lambda using the Serverless Express adapter.

### Prerequisites

Install the required dependency:

```bash
npm install @codegenie/serverless-express
```

### Setup

<Tip>
Projects created with `frontmcp create --target lambda` include a SAM template at `ci/template.yaml` and a deploy script:
```bash
npm run deploy  # Runs: cd ci && sam build && sam deploy
```
</Tip>

1. Build your project:

   ```bash
   frontmcp build --adapter lambda
   ```

2. This generates:

   ```
   dist/
     main.js      # Your compiled server
     index.js     # Lambda handler wrapper
   ```

3. Deploy using your preferred AWS deployment tool.

### Example SAM Template

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31

Resources:
  FrontMcpFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: dist/index.handler
      Runtime: nodejs20.x
      Timeout: 30
      MemorySize: 256
      Events:
        Api:
          Type: Api
          Properties:
            Path: /{proxy+}
            Method: ANY
```

### Example serverless.yml

```yaml
service: frontmcp-server

provider:
  name: aws
  runtime: nodejs20.x
  stage: ${opt:stage, 'dev'}

functions:
  api:
    handler: dist/index.handler
    events:
      - http:
          path: /{proxy+}
          method: ANY
```

### ESM Requirements

<Note>
AWS Lambda with ESM requires one of:
- `"type": "module"` in your `package.json`
- Using `.mjs` extension for handler files
- Configuring your deployment tool for ESM

The generated `dist/index.js` uses ESM syntax (`import`/`export`).

</Note>

### Cold Start Optimization

Lambda cold starts can add latency to the first request. Consider:

- **Provisioned Concurrency**: Keep instances warm
- **Smaller bundle size**: Use tree-shaking and minimize dependencies
- **ARM64 architecture**: Often faster cold starts than x86

## Cloudflare Workers (Experimental)

<Warning>
Cloudflare Workers support is **experimental**. The Express-to-Workers adapter has limitations
with streaming, certain middleware, and some response methods.

For production Cloudflare deployments, consider using [Hono](https://hono.dev/) or native Workers APIs.

</Warning>

<Tip>
Projects created with `frontmcp create --target cloudflare` include a `wrangler.toml` and a deploy script:
```bash
npm run deploy  # Runs: wrangler deploy
```
</Tip>

### Limitations

- Basic request/response handling only
- No streaming support
- Limited Express middleware compatibility
- Missing some response methods (`redirect()`, `type()`, etc.)

### Setup

1. Build your project:

   ```bash
   frontmcp build --adapter cloudflare
   ```

2. This generates:

   ```
   dist/
     main.js      # Your compiled server
     index.js     # Cloudflare handler wrapper
   wrangler.toml  # Wrangler configuration
   ```

3. Deploy:
   ```bash
   wrangler deploy
   ```

### Generated wrangler.toml

```toml
name = "frontmcp-worker"
main = "dist/index.js"
compatibility_date = "2024-01-01"
```

## How Serverless Mode Works

### Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Build Time                               │
├─────────────────────────────────────────────────────────────┤
│  frontmcp build --adapter vercel                            │
│       │                                                      │
│       ├── Compiles TypeScript with --module esnext          │
│       ├── Generates platform-specific index.js wrapper      │
│       └── Creates platform config (vercel.json, etc.)       │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                     Runtime                                  │
├─────────────────────────────────────────────────────────────┤
│  1. Platform invokes index.js                               │
│  2. index.js sets FRONTMCP_SERVERLESS=1                     │
│  3. index.js imports main.js                                │
│  4. @FrontMcp decorator detects serverless mode             │
│  5. Decorator calls createHandler() instead of bootstrap()  │
│  6. Express app stored globally via setServerlessHandler()  │
│  7. index.js calls getServerlessHandlerAsync()              │
│  8. Requests are forwarded to the Express app               │
└──────────────────────────────────────────────
```
